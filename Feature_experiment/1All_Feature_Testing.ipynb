{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"All_Feature_Testing.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1zT1IpyXyk6NCSgT8M948JJozqPJOlge9","authorship_tag":"ABX9TyO3j75nvdBzrxx+CedOOmrq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"xYb5w-RufDlk","colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"status":"error","timestamp":1627869908966,"user_tz":-60,"elapsed":12269,"user":{"displayName":"Pasinpat Vitoochuleechoti","photoUrl":"","userId":"04423538674438574487"}},"outputId":"a29fc209-d5f7-44ab-e312-dc9cf5c8fcee"},"source":["import pandas as pd\n","import numpy as np\n","from IPython.display import display\n","from fastai.imports import *\n","from sklearn import metrics\n","from pandas.tseries.offsets import DateOffset\n","import matplotlib.pyplot as plt\n","\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","\n","hour_ahead = 24\n","n_estimators = 80\n","learning_rate = 0.1\n","Depth = 6\n","Min_leaf = 20\n","Top = 30\n","\n","path = \"/content/drive/MyDrive/Colab Notebooks/Project/06_Weather_FI_Time.csv\"\n","Merge_all = pd.read_csv(path)\n","dti = pd.to_datetime(Merge_all['DateTime'], format='%m/%d/%Y %H', exact=False)\n","Merge_all.set_index(pd.Index(dti), inplace=True)\n","Merge_all.drop(['DateTime'], axis=1, inplace=True)\n","\n","First = Merge_all.iloc[0:11000, :]\n","N_index = First.shape\n","Y_temp = First['FI']\n","Y = Y_temp.iloc[hour_ahead:N_index[0]]\n","#Y.reset_index(drop=True, inplace=True)\n","#Y.columns = [''] * len(Y.columns)\n","\n","\n","X_temp1 = First.drop(First.columns.difference(['FI', 'C_SE1 > FI', 'C_FI > SE1', 'C_SE3 > FI', 'C_FI > SE3', 'C_EE > FI', 'C_FI > EE', 'F_FI > SE1', 'F_SE1 > FI', 'F_FI > SE3', 'F_SE3 > FI', 'F_FI > EE', 'F_EE > FI', 'FI Buy', 'FI Sell']), axis=1)\n","X_temp2 = First.drop(['FI', 'C_SE1 > FI', 'C_FI > SE1', 'C_SE3 > FI', 'C_FI > SE3', 'C_EE > FI', 'C_FI > EE', 'F_FI > SE1', 'F_SE1 > FI', 'F_FI > SE3', 'F_SE3 > FI', 'F_FI > EE', 'F_EE > FI', 'FI Buy', 'FI Sell'], axis=1)\n","X_temp2_index = X_temp2.index + DateOffset(hours=-hour_ahead)\n","X_temp2.set_index(X_temp2_index, inplace=True)\n","#X_temp1 = X_temp1.to_frame()\n","X_temp = X_temp1.join(X_temp2)\n","X = X_temp.iloc[0:N_index[0] - hour_ahead]\n","\n","#X.reset_index(drop=True, inplace=True)\n","#X.columns = [''] * len(X.columns)\n","Pred_index = X.shape\n","print(\"Shape = \"+str(Pred_index))\n","\n","Y_temp = Y.copy()\n","Y_temp.index = Y_temp.index + DateOffset(hours=-hour_ahead)\n","Y_temp.rename('Y', inplace=True)\n","XY = X.copy()\n","XY = XY.join(Y_temp)\n","XYC = XY.corr()\n","YCorr = XYC.drop(First.columns.difference(['Y']), axis=1)\n","YCorrABS = YCorr.abs()\n","YCorrABS.sort_values(by=['Y'], inplace=True)\n","\n","\n","\n","TopIndex = YCorrABS.index[(803-Top):803] \n","X.drop(X.columns.difference(TopIndex), axis=1, inplace=True)\n","\n","\n","\n","\n","X = X.to_numpy()\n","Y = Y.to_numpy()\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n","\n","\n","\n","class DecisionTree():\n","    def __init__(self, x, y, n_features, f_idxs, idxs=None, depth=3, min_leaf=5):\n","        if idxs is None: idxs=np.arange(len(y))\n","        self.x, self.y, self.idxs, self.min_leaf, self.f_idxs = x, y, idxs, min_leaf, f_idxs\n","        self.depth = depth\n","        #print(f_idxs)\n","        #         print(self.depth)\n","        self.n_features = n_features\n","        self.n, self.c = len(idxs), x.shape[1]\n","        self.val = np.mean(y[idxs])\n","        self.score = float('inf')\n","        self.find_varsplit()\n","\n","    def find_varsplit(self):\n","        for i in self.f_idxs: self.find_better_split(i)\n","        if self.is_leaf: return\n","        x = self.split_col\n","        lhs = np.nonzero(x <= self.split)[0]\n","        rhs = np.nonzero(x > self.split)[0]\n","        lf_idxs = np.random.permutation(self.x.shape[1])[:self.n_features]\n","        rf_idxs = np.random.permutation(self.x.shape[1])[:self.n_features]\n","        self.lhs = DecisionTree(self.x, self.y, self.n_features, lf_idxs, self.idxs[lhs], depth=self.depth - 1,\n","                                min_leaf=self.min_leaf)\n","        self.rhs = DecisionTree(self.x, self.y, self.n_features, rf_idxs, self.idxs[rhs], depth=self.depth - 1,\n","                                min_leaf=self.min_leaf)\n","\n","    def find_better_split(self, var_idx):\n","        x, y = self.x[self.idxs, var_idx], self.y[self.idxs]\n","        sort_idx = np.argsort(x)\n","        sort_y, sort_x = y[sort_idx], x[sort_idx]\n","        rhs_sum2: object\n","        rhs_cnt, rhs_sum, rhs_sum2 = self.n, sort_y.sum(), (sort_y ** 2).sum()\n","        lhs_cnt, lhs_sum, lhs_sum2 = 0, 0., 0.\n","\n","        for i in range(0, self.n - self.min_leaf - 1):\n","            xi, yi = sort_x[i], sort_y[i]\n","            lhs_cnt += 1\n","            rhs_cnt -= 1\n","            lhs_sum += yi\n","            rhs_sum -= yi\n","            lhs_sum2 += yi ** 2\n","            rhs_sum2 -= yi ** 2\n","            if i < self.min_leaf or xi == sort_x[i + 1]:\n","                continue\n","\n","            lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)\n","            rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)\n","            curr_score = lhs_std * lhs_cnt + rhs_std * rhs_cnt\n","            if curr_score < self.score:\n","                self.var_idx, self.score, self.split = var_idx, curr_score, xi\n","\n","    @property\n","    def split_name(self):\n","        return self.x.columns[self.var_idx]\n","\n","    @property\n","    def split_col(self):\n","        return self.x[self.idxs, self.var_idx]\n","\n","    @property\n","    def is_leaf(self):\n","        return self.score == float('inf') or self.depth <= 0\n","\n","    def predict(self, x):\n","        return np.array([self.predict_row(xi) for xi in x])\n","\n","    def predict_row(self, xi):\n","        if self.is_leaf: return self.val\n","        t = self.lhs if xi[self.var_idx] <= self.split else self.rhs\n","        return t.predict_row(xi)\n","\n","def std_agg(cnt, s1, s2):\n","    try:\n","        return math.sqrt((s2 / cnt) - (s1 / cnt) ** 2)\n","    except:\n","        return 0\n","\n","xi = X_train\n","train_index = X_train.shape\n","yi = y_train - np.mean(y_train)\n","ei = 0  # initialization of error\n","predf = np.mean(y_train)  # initial prediction 0\n","\n","\n","def create_tree(x, y, n_features, sample_sz, depth=3, min_leaf=5):\n","    idxs = np.random.permutation(len(y))[:sample_sz]\n","    f_idxs = np.random.permutation(x.shape[1])[:n_features]\n","    return DecisionTree(x[idxs], y[idxs], n_features, f_idxs,\n","                        idxs=np.array(range(sample_sz)), depth=depth, min_leaf=min_leaf)\n","\n","\n","print(\"hour_ahead = \" + str(hour_ahead))\n","print(\"n_estimators = \" + str(n_estimators))\n","print(\"learning_rate = \" + str(learning_rate))\n","print(\"Depth = \" + str(Depth))\n","print(\"Min_leaf = \" + str(Min_leaf))\n","\n","\n","trees = []\n","for i in range(n_estimators):\n","    tree = create_tree(xi, yi, train_index[1], train_index[0], depth=Depth, min_leaf=Min_leaf)\n","    predi = tree.predict(xi)\n","    predf = predf + learning_rate * predi\n","    print(str(i)+str(\"  \")+str(mean_absolute_error(y_train, predf)))\n","    ei = y_train - predf  # needed originl y here as residual always from original y\n","    yi = ei  # update yi as residual to reloop\n","    trees.append(tree)\n","\n","\n","MSE = mean_squared_error(y_train, predf, squared=True)\n","print(\"Training MSE  \" + str(MSE))\n","RMSE = np.sqrt(MSE)\n","print(\"Training RMSE  \" + str(RMSE))\n","MAE = mean_absolute_error(y_train, predf)\n","print(\"Training MAE  \" + str(MAE))\n","\n","\n","\n","xi = X_test\n","train_index = X_test.shape\n","yi = y_test - np.mean(y_test)\n","ei = 0  # initialization of error\n","predf = np.mean(y_test)\n","\n","i = 0\n","for t in trees:\n","    predi = t.predict(X_test)\n","    predf = predf + learning_rate * predi\n","    print(str(i)+str(\"  \")+str(np.sqrt(mean_squared_error(y_test, predf, squared=True))))\n","    print(str(i)+str(\"  \")+str(mean_absolute_error(y_test, predf)))\n","    ei = y_test - predf  # needed originl y here as residual always from original y\n","    yi = ei  # update yi as residual to reloop\n","\n","    #if i == 1:\n","    #   break\n","    i += 1\n","\n","\n","MSE = mean_squared_error(y_test, predf, squared=True)\n","print(\"Testing MSE  \" + str(MSE))\n","RMSE = np.sqrt(MSE)\n","print(\"Testing RMSE  \" + str(RMSE))\n","MAE = mean_absolute_error(y_test, predf)\n","print(\"Testing MAE  \" + str(MAE))\n","\n","\n","plt.figure(figsize=(10, 6), dpi=80)\n","plt.suptitle('Gradient boosting regressor (Test) N=' + str(Pred_index[0]))\n","plt.plot(np.arange(len(y_test))+1, y_test, color=\"blue\", linewidth=2.5, linestyle=\"-\", label='Real Price')\n","plt.plot(np.arange(len(predf))+1, predf, color=\"red\",  linewidth=2.5, linestyle=\"-\", label='Predicted Price')\n","plt.xlabel('Hours')\n","plt.ylabel('Price(EUR)')\n","plt.legend(frameon=False)\n","plt.show()"],"execution_count":3,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mdta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-9d79834c8c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/Project/06_Weather_FI_Time.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mMerge_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMerge_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DateTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%m/%d/%Y %H'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mMerge_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mMerge_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DateTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                     result, timezones = array_strptime(\n\u001b[0;32m--> 418\u001b[0;31m                         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                     )\n\u001b[1;32m    420\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"%Z\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"%z\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/tslibs/strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: time data '2013-01-01 00:00:00' does not match format '%m/%d/%Y %H' (search)"]}]},{"cell_type":"code","metadata":{"id":"rxW5wkLq0xa6","executionInfo":{"status":"aborted","timestamp":1627869908963,"user_tz":-60,"elapsed":4,"user":{"displayName":"Pasinpat Vitoochuleechoti","photoUrl":"","userId":"04423538674438574487"}}},"source":["import pandas as pd\n","import numpy as np\n","from IPython.display import display\n","from fastai.imports import *\n","from sklearn import metrics\n","from pandas.tseries.offsets import DateOffset\n","import matplotlib.pyplot as plt\n","\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","\n","hour_ahead = 24\n","n_estimators = 80\n","learning_rate = 0.1\n","Depth = 6\n","Min_leaf = 20\n","Top = 30\n","\n","path = \"/content/drive/MyDrive/Colab Notebooks/Project/04_All_Feature.csv\"\n","Merge_all = pd.read_csv(path)\n","dti = pd.to_datetime(Merge_all['DateTime'], format='%m/%d/%Y %H', exact=False)\n","Merge_all.set_index(pd.Index(dti), inplace=True)\n","Merge_all.drop(['DateTime'], axis=1, inplace=True)\n","\n","First = Merge_all.iloc[0:11000, :]\n","N_index = First.shape\n","Y_temp = First['FI']\n","Y = Y_temp.iloc[hour_ahead:N_index[0]]\n","#Y.reset_index(drop=True, inplace=True)\n","#Y.columns = [''] * len(Y.columns)\n","\n","\n","X_temp1 = First.drop(First.columns.difference(['FI', 'C_SE1 > FI', 'C_FI > SE1', 'C_SE3 > FI', 'C_FI > SE3', 'C_EE > FI', 'C_FI > EE', 'F_FI > SE1', 'F_SE1 > FI', 'F_FI > SE3', 'F_SE3 > FI', 'F_FI > EE', 'F_EE > FI', 'FI Buy', 'FI Sell']), axis=1)\n","X_temp2 = First.drop(['FI', 'C_SE1 > FI', 'C_FI > SE1', 'C_SE3 > FI', 'C_FI > SE3', 'C_EE > FI', 'C_FI > EE', 'F_FI > SE1', 'F_SE1 > FI', 'F_FI > SE3', 'F_SE3 > FI', 'F_FI > EE', 'F_EE > FI', 'FI Buy', 'FI Sell'], axis=1)\n","X_temp2_index = X_temp2.index + DateOffset(hours=-hour_ahead)\n","X_temp2.set_index(X_temp2_index, inplace=True)\n","#X_temp1 = X_temp1.to_frame()\n","X_temp = X_temp1.join(X_temp2)\n","X = X_temp.iloc[0:N_index[0] - hour_ahead]\n","\n","#X.reset_index(drop=True, inplace=True)\n","#X.columns = [''] * len(X.columns)\n","Pred_index = X.shape\n","print(\"Shape = \"+str(Pred_index))\n","\n","Y_temp = Y.copy()\n","Y_temp.index = Y_temp.index + DateOffset(hours=-hour_ahead)\n","Y_temp.rename('Y', inplace=True)\n","XY = X.copy()\n","XY = XY.join(Y_temp)\n","XYC2 = XY.corr(method='spearman')\n","YCorr2 = XYC2.drop(First.columns.difference(['Y']), axis=1)\n","YCorr2ABS = YCorr2.abs()\n","YCorr2ABS.sort_values(by=['Y'], inplace=True)\n","\n","\n","\n","\n","TopIndex = YCorr2ABS.index[(803-Top):803] \n","X.drop(X.columns.difference(TopIndex), axis=1, inplace=True)\n","\n","\n","\n","\n","X = X.to_numpy()\n","Y = Y.to_numpy()\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n","\n","\n","\n","class DecisionTree():\n","    def __init__(self, x, y, n_features, f_idxs, idxs=None, depth=3, min_leaf=5):\n","        if idxs is None: idxs=np.arange(len(y))\n","        self.x, self.y, self.idxs, self.min_leaf, self.f_idxs = x, y, idxs, min_leaf, f_idxs\n","        self.depth = depth\n","        #print(f_idxs)\n","        #         print(self.depth)\n","        self.n_features = n_features\n","        self.n, self.c = len(idxs), x.shape[1]\n","        self.val = np.mean(y[idxs])\n","        self.score = float('inf')\n","        self.find_varsplit()\n","\n","    def find_varsplit(self):\n","        for i in self.f_idxs: self.find_better_split(i)\n","        if self.is_leaf: return\n","        x = self.split_col\n","        lhs = np.nonzero(x <= self.split)[0]\n","        rhs = np.nonzero(x > self.split)[0]\n","        lf_idxs = np.random.permutation(self.x.shape[1])[:self.n_features]\n","        rf_idxs = np.random.permutation(self.x.shape[1])[:self.n_features]\n","        self.lhs = DecisionTree(self.x, self.y, self.n_features, lf_idxs, self.idxs[lhs], depth=self.depth - 1,\n","                                min_leaf=self.min_leaf)\n","        self.rhs = DecisionTree(self.x, self.y, self.n_features, rf_idxs, self.idxs[rhs], depth=self.depth - 1,\n","                                min_leaf=self.min_leaf)\n","\n","    def find_better_split(self, var_idx):\n","        x, y = self.x[self.idxs, var_idx], self.y[self.idxs]\n","        sort_idx = np.argsort(x)\n","        sort_y, sort_x = y[sort_idx], x[sort_idx]\n","        rhs_sum2: object\n","        rhs_cnt, rhs_sum, rhs_sum2 = self.n, sort_y.sum(), (sort_y ** 2).sum()\n","        lhs_cnt, lhs_sum, lhs_sum2 = 0, 0., 0.\n","\n","        for i in range(0, self.n - self.min_leaf - 1):\n","            xi, yi = sort_x[i], sort_y[i]\n","            lhs_cnt += 1\n","            rhs_cnt -= 1\n","            lhs_sum += yi\n","            rhs_sum -= yi\n","            lhs_sum2 += yi ** 2\n","            rhs_sum2 -= yi ** 2\n","            if i < self.min_leaf or xi == sort_x[i + 1]:\n","                continue\n","\n","            lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)\n","            rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)\n","            curr_score = lhs_std * lhs_cnt + rhs_std * rhs_cnt\n","            if curr_score < self.score:\n","                self.var_idx, self.score, self.split = var_idx, curr_score, xi\n","\n","    @property\n","    def split_name(self):\n","        return self.x.columns[self.var_idx]\n","\n","    @property\n","    def split_col(self):\n","        return self.x[self.idxs, self.var_idx]\n","\n","    @property\n","    def is_leaf(self):\n","        return self.score == float('inf') or self.depth <= 0\n","\n","    def predict(self, x):\n","        return np.array([self.predict_row(xi) for xi in x])\n","\n","    def predict_row(self, xi):\n","        if self.is_leaf: return self.val\n","        t = self.lhs if xi[self.var_idx] <= self.split else self.rhs\n","        return t.predict_row(xi)\n","\n","def std_agg(cnt, s1, s2):\n","    try:\n","        return math.sqrt((s2 / cnt) - (s1 / cnt) ** 2)\n","    except:\n","        return 0\n","\n","xi = X_train\n","train_index = X_train.shape\n","yi = y_train - np.mean(y_train)\n","ei = 0  # initialization of error\n","predf = np.mean(y_train)  # initial prediction 0\n","\n","\n","def create_tree(x, y, n_features, sample_sz, depth=3, min_leaf=5):\n","    idxs = np.random.permutation(len(y))[:sample_sz]\n","    f_idxs = np.random.permutation(x.shape[1])[:n_features]\n","    return DecisionTree(x[idxs], y[idxs], n_features, f_idxs,\n","                        idxs=np.array(range(sample_sz)), depth=depth, min_leaf=min_leaf)\n","\n","\n","print(\"hour_ahead = \" + str(hour_ahead))\n","print(\"n_estimators = \" + str(n_estimators))\n","print(\"learning_rate = \" + str(learning_rate))\n","print(\"Depth = \" + str(Depth))\n","print(\"Min_leaf = \" + str(Min_leaf))\n","\n","\n","trees = []\n","for i in range(n_estimators):\n","    tree = create_tree(xi, yi, train_index[1], train_index[0], depth=Depth, min_leaf=Min_leaf)\n","    predi = tree.predict(xi)\n","    predf = predf + learning_rate * predi\n","    print(str(i)+str(\"  \")+str(mean_absolute_error(y_train, predf)))\n","    ei = y_train - predf  # needed originl y here as residual always from original y\n","    yi = ei  # update yi as residual to reloop\n","    trees.append(tree)\n","\n","\n","MSE = mean_squared_error(y_train, predf, squared=True)\n","print(\"Training MSE  \" + str(MSE))\n","RMSE = np.sqrt(MSE)\n","print(\"Training RMSE  \" + str(RMSE))\n","MAE = mean_absolute_error(y_train, predf)\n","print(\"Training MAE  \" + str(MAE))\n","\n","\n","\n","xi = X_test\n","train_index = X_test.shape\n","yi = y_test - np.mean(y_test)\n","ei = 0  # initialization of error\n","predf = np.mean(y_test)\n","\n","i = 0\n","for t in trees:\n","    predi = t.predict(X_test)\n","    predf = predf + learning_rate * predi\n","    print(str(i)+str(\"  \")+str(np.sqrt(mean_squared_error(y_test, predf, squared=True))))\n","    print(str(i)+str(\"  \")+str(mean_absolute_error(y_test, predf)))\n","    ei = y_test - predf  # needed originl y here as residual always from original y\n","    yi = ei  # update yi as residual to reloop\n","\n","    #if i == 1:\n","    #   break\n","    i += 1\n","\n","\n","MSE = mean_squared_error(y_test, predf, squared=True)\n","print(\"Testing MSE  \" + str(MSE))\n","RMSE = np.sqrt(MSE)\n","print(\"Testing RMSE  \" + str(RMSE))\n","MAE = mean_absolute_error(y_test, predf)\n","print(\"Testing MAE  \" + str(MAE))\n","\n","\n","plt.figure(figsize=(10, 6), dpi=80)\n","plt.suptitle('Gradient boosting regressor (Test) N=' + str(Pred_index[0]))\n","plt.plot(np.arange(len(y_test))+1, y_test, color=\"blue\", linewidth=2.5, linestyle=\"-\", label='Real Price')\n","plt.plot(np.arange(len(predf))+1, predf, color=\"red\",  linewidth=2.5, linestyle=\"-\", label='Predicted Price')\n","plt.xlabel('Hours')\n","plt.ylabel('Price(EUR)')\n","plt.legend(frameon=False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OImWE-Ad0IoD","executionInfo":{"status":"aborted","timestamp":1627869908965,"user_tz":-60,"elapsed":6,"user":{"displayName":"Pasinpat Vitoochuleechoti","photoUrl":"","userId":"04423538674438574487"}}},"source":["import pandas as pd\n","import numpy as np\n","from IPython.display import display\n","from fastai.imports import *\n","from sklearn import metrics\n","from pandas.tseries.offsets import DateOffset\n","import matplotlib.pyplot as plt\n","\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","\n","hour_ahead = 24\n","n_estimators = 80\n","learning_rate = 0.1\n","Depth = 6\n","Min_leaf = 20\n","Top = 30\n","\n","path = \"/content/drive/MyDrive/Colab Notebooks/Project/04_All_Feature.csv\"\n","Merge_all = pd.read_csv(path)\n","dti = pd.to_datetime(Merge_all['DateTime'], format='%m/%d/%Y %H', exact=False)\n","Merge_all.set_index(pd.Index(dti), inplace=True)\n","Merge_all.drop(['DateTime'], axis=1, inplace=True)\n","\n","First = Merge_all.iloc[0:11000, :]\n","N_index = First.shape\n","Y_temp = First['FI']\n","Y = Y_temp.iloc[hour_ahead:N_index[0]]\n","#Y.reset_index(drop=True, inplace=True)\n","#Y.columns = [''] * len(Y.columns)\n","\n","\n","X_temp1 = First.drop(First.columns.difference(['FI', 'C_SE1 > FI', 'C_FI > SE1', 'C_SE3 > FI', 'C_FI > SE3', 'C_EE > FI', 'C_FI > EE', 'F_FI > SE1', 'F_SE1 > FI', 'F_FI > SE3', 'F_SE3 > FI', 'F_FI > EE', 'F_EE > FI', 'FI Buy', 'FI Sell']), axis=1)\n","X_temp2 = First.drop(['FI', 'C_SE1 > FI', 'C_FI > SE1', 'C_SE3 > FI', 'C_FI > SE3', 'C_EE > FI', 'C_FI > EE', 'F_FI > SE1', 'F_SE1 > FI', 'F_FI > SE3', 'F_SE3 > FI', 'F_FI > EE', 'F_EE > FI', 'FI Buy', 'FI Sell'], axis=1)\n","X_temp2_index = X_temp2.index + DateOffset(hours=-hour_ahead)\n","X_temp2.set_index(X_temp2_index, inplace=True)\n","#X_temp1 = X_temp1.to_frame()\n","X_temp = X_temp1.join(X_temp2)\n","X = X_temp.iloc[0:N_index[0] - hour_ahead]\n","\n","#X.reset_index(drop=True, inplace=True)\n","#X.columns = [''] * len(X.columns)\n","Pred_index = X.shape\n","print(\"Shape = \"+str(Pred_index))\n","\n","from xgboost import XGBRegressor\n","model = XGBRegressor()\n","model.fit(X, Y)\n","importance = model.feature_importances_\n","Feature = []\n","Feature_index = X.columns\n","for i, v in enumerate(importance):\n","    Feature.append(v)\n","\n","Yfi = pd.DataFrame({'Index':Feature_index})\n","Yf = pd.DataFrame({'Y':Feature})\n","Yf.index = Yfi['Index']\n","Yf.sort_values(by=['Y'], inplace=True)\n","\n","\n","\n","\n","TopIndex = Yf.index[(803-Top):803] \n","X.drop(X.columns.difference(TopIndex), axis=1, inplace=True)\n","\n","\n","\n","\n","X = X.to_numpy()\n","Y = Y.to_numpy()\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n","\n","\n","\n","class DecisionTree():\n","    def __init__(self, x, y, n_features, f_idxs, idxs=None, depth=3, min_leaf=5):\n","        if idxs is None: idxs=np.arange(len(y))\n","        self.x, self.y, self.idxs, self.min_leaf, self.f_idxs = x, y, idxs, min_leaf, f_idxs\n","        self.depth = depth\n","        #print(f_idxs)\n","        #         print(self.depth)\n","        self.n_features = n_features\n","        self.n, self.c = len(idxs), x.shape[1]\n","        self.val = np.mean(y[idxs])\n","        self.score = float('inf')\n","        self.find_varsplit()\n","\n","    def find_varsplit(self):\n","        for i in self.f_idxs: self.find_better_split(i)\n","        if self.is_leaf: return\n","        x = self.split_col\n","        lhs = np.nonzero(x <= self.split)[0]\n","        rhs = np.nonzero(x > self.split)[0]\n","        lf_idxs = np.random.permutation(self.x.shape[1])[:self.n_features]\n","        rf_idxs = np.random.permutation(self.x.shape[1])[:self.n_features]\n","        self.lhs = DecisionTree(self.x, self.y, self.n_features, lf_idxs, self.idxs[lhs], depth=self.depth - 1,\n","                                min_leaf=self.min_leaf)\n","        self.rhs = DecisionTree(self.x, self.y, self.n_features, rf_idxs, self.idxs[rhs], depth=self.depth - 1,\n","                                min_leaf=self.min_leaf)\n","\n","    def find_better_split(self, var_idx):\n","        x, y = self.x[self.idxs, var_idx], self.y[self.idxs]\n","        sort_idx = np.argsort(x)\n","        sort_y, sort_x = y[sort_idx], x[sort_idx]\n","        rhs_sum2: object\n","        rhs_cnt, rhs_sum, rhs_sum2 = self.n, sort_y.sum(), (sort_y ** 2).sum()\n","        lhs_cnt, lhs_sum, lhs_sum2 = 0, 0., 0.\n","\n","        for i in range(0, self.n - self.min_leaf - 1):\n","            xi, yi = sort_x[i], sort_y[i]\n","            lhs_cnt += 1\n","            rhs_cnt -= 1\n","            lhs_sum += yi\n","            rhs_sum -= yi\n","            lhs_sum2 += yi ** 2\n","            rhs_sum2 -= yi ** 2\n","            if i < self.min_leaf or xi == sort_x[i + 1]:\n","                continue\n","\n","            lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)\n","            rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)\n","            curr_score = lhs_std * lhs_cnt + rhs_std * rhs_cnt\n","            if curr_score < self.score:\n","                self.var_idx, self.score, self.split = var_idx, curr_score, xi\n","\n","    @property\n","    def split_name(self):\n","        return self.x.columns[self.var_idx]\n","\n","    @property\n","    def split_col(self):\n","        return self.x[self.idxs, self.var_idx]\n","\n","    @property\n","    def is_leaf(self):\n","        return self.score == float('inf') or self.depth <= 0\n","\n","    def predict(self, x):\n","        return np.array([self.predict_row(xi) for xi in x])\n","\n","    def predict_row(self, xi):\n","        if self.is_leaf: return self.val\n","        t = self.lhs if xi[self.var_idx] <= self.split else self.rhs\n","        return t.predict_row(xi)\n","\n","def std_agg(cnt, s1, s2):\n","    try:\n","        return math.sqrt((s2 / cnt) - (s1 / cnt) ** 2)\n","    except:\n","        return 0\n","\n","xi = X_train\n","train_index = X_train.shape\n","yi = y_train - np.mean(y_train)\n","ei = 0  # initialization of error\n","predf = np.mean(y_train)  # initial prediction 0\n","\n","\n","def create_tree(x, y, n_features, sample_sz, depth=3, min_leaf=5):\n","    idxs = np.random.permutation(len(y))[:sample_sz]\n","    f_idxs = np.random.permutation(x.shape[1])[:n_features]\n","    return DecisionTree(x[idxs], y[idxs], n_features, f_idxs,\n","                        idxs=np.array(range(sample_sz)), depth=depth, min_leaf=min_leaf)\n","\n","\n","print(\"hour_ahead = \" + str(hour_ahead))\n","print(\"n_estimators = \" + str(n_estimators))\n","print(\"learning_rate = \" + str(learning_rate))\n","print(\"Depth = \" + str(Depth))\n","print(\"Min_leaf = \" + str(Min_leaf))\n","\n","\n","trees = []\n","for i in range(n_estimators):\n","    tree = create_tree(xi, yi, train_index[1], train_index[0], depth=Depth, min_leaf=Min_leaf)\n","    predi = tree.predict(xi)\n","    predf = predf + learning_rate * predi\n","    print(str(i)+str(\"  \")+str(mean_absolute_error(y_train, predf)))\n","    ei = y_train - predf  # needed originl y here as residual always from original y\n","    yi = ei  # update yi as residual to reloop\n","    trees.append(tree)\n","\n","\n","MSE = mean_squared_error(y_train, predf, squared=True)\n","print(\"Training MSE  \" + str(MSE))\n","RMSE = np.sqrt(MSE)\n","print(\"Training RMSE  \" + str(RMSE))\n","MAE = mean_absolute_error(y_train, predf)\n","print(\"Training MAE  \" + str(MAE))\n","\n","\n","\n","xi = X_test\n","train_index = X_test.shape\n","yi = y_test - np.mean(y_test)\n","ei = 0  # initialization of error\n","predf = np.mean(y_test)\n","\n","i = 0\n","for t in trees:\n","    predi = t.predict(X_test)\n","    predf = predf + learning_rate * predi\n","    print(str(i)+str(\"  \")+str(np.sqrt(mean_squared_error(y_test, predf, squared=True))))\n","    print(str(i)+str(\"  \")+str(mean_absolute_error(y_test, predf)))\n","    ei = y_test - predf  # needed originl y here as residual always from original y\n","    yi = ei  # update yi as residual to reloop\n","\n","    #if i == 1:\n","    #   break\n","    i += 1\n","\n","\n","MSE = mean_squared_error(y_test, predf, squared=True)\n","print(\"Testing MSE  \" + str(MSE))\n","RMSE = np.sqrt(MSE)\n","print(\"Testing RMSE  \" + str(RMSE))\n","MAE = mean_absolute_error(y_test, predf)\n","print(\"Testing MAE  \" + str(MAE))\n","\n","\n","plt.figure(figsize=(10, 6), dpi=80)\n","plt.suptitle('Gradient boosting regressor (Test) N=' + str(Pred_index[0]))\n","plt.plot(np.arange(len(y_test))+1, y_test, color=\"blue\", linewidth=2.5, linestyle=\"-\", label='Real Price')\n","plt.plot(np.arange(len(predf))+1, predf, color=\"red\",  linewidth=2.5, linestyle=\"-\", label='Predicted Price')\n","plt.xlabel('Hours')\n","plt.ylabel('Price(EUR)')\n","plt.legend(frameon=False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbfHb5ec20eD","executionInfo":{"status":"aborted","timestamp":1627869908966,"user_tz":-60,"elapsed":7,"user":{"displayName":"Pasinpat Vitoochuleechoti","photoUrl":"","userId":"04423538674438574487"}}},"source":["import pandas as pd\n","import numpy as np\n","from IPython.display import display\n","from fastai.imports import *\n","from sklearn import metrics\n","from pandas.tseries.offsets import DateOffset\n","import matplotlib.pyplot as plt\n","\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","\n","hour_ahead = 24\n","n_estimators = 80\n","learning_rate = 0.1\n","Depth = 6\n","Min_leaf = 20\n","Top = 30\n","\n","path = \"/content/drive/MyDrive/Colab Notebooks/Project/04_All_Feature.csv\"\n","Merge_all = pd.read_csv(path)\n","dti = pd.to_datetime(Merge_all['DateTime'], format='%m/%d/%Y %H', exact=False)\n","Merge_all.set_index(pd.Index(dti), inplace=True)\n","Merge_all.drop(['DateTime'], axis=1, inplace=True)\n","\n","First = Merge_all.iloc[0:11000, :]\n","N_index = First.shape\n","Y_temp = First['FI']\n","Y = Y_temp.iloc[hour_ahead:N_index[0]]\n","#Y.reset_index(drop=True, inplace=True)\n","#Y.columns = [''] * len(Y.columns)\n","\n","\n","X_temp1 = First.drop(First.columns.difference(['FI', 'C_SE1 > FI', 'C_FI > SE1', 'C_SE3 > FI', 'C_FI > SE3', 'C_EE > FI', 'C_FI > EE', 'F_FI > SE1', 'F_SE1 > FI', 'F_FI > SE3', 'F_SE3 > FI', 'F_FI > EE', 'F_EE > FI', 'FI Buy', 'FI Sell']), axis=1)\n","X_temp2 = First.drop(['FI', 'C_SE1 > FI', 'C_FI > SE1', 'C_SE3 > FI', 'C_FI > SE3', 'C_EE > FI', 'C_FI > EE', 'F_FI > SE1', 'F_SE1 > FI', 'F_FI > SE3', 'F_SE3 > FI', 'F_FI > EE', 'F_EE > FI', 'FI Buy', 'FI Sell'], axis=1)\n","X_temp2_index = X_temp2.index + DateOffset(hours=-hour_ahead)\n","X_temp2.set_index(X_temp2_index, inplace=True)\n","#X_temp1 = X_temp1.to_frame()\n","X_temp = X_temp1.join(X_temp2)\n","X = X_temp.iloc[0:N_index[0] - hour_ahead]\n","\n","#X.reset_index(drop=True, inplace=True)\n","#X.columns = [''] * len(X.columns)\n","Pred_index = X.shape\n","print(\"Shape = \"+str(Pred_index))\n","\n","from sklearn.linear_model import LinearRegression\n","model2 = LinearRegression()\n","model2.fit(X, Y)\n","importance2 = model2.coef_\n","FeatureR = []\n","FeatureR_index = X.columns\n","for i,v in enumerate(importance2):\n","    FeatureR.append(v)\n","\n","Yfri = pd.DataFrame({'Index':FeatureR_index})\n","Yfr = pd.DataFrame({'Y':FeatureR})\n","Yfr.index = Yfri['Index']\n","Yfr.sort_values(by=['Y'], inplace=True)\n","\n","\n","\n","\n","TopIndex = Yfr.index[(803-Top):803] \n","X.drop(X.columns.difference(TopIndex), axis=1, inplace=True)\n","\n","\n","\n","\n","X = X.to_numpy()\n","Y = Y.to_numpy()\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n","\n","\n","\n","class DecisionTree():\n","    def __init__(self, x, y, n_features, f_idxs, idxs=None, depth=3, min_leaf=5):\n","        if idxs is None: idxs=np.arange(len(y))\n","        self.x, self.y, self.idxs, self.min_leaf, self.f_idxs = x, y, idxs, min_leaf, f_idxs\n","        self.depth = depth\n","        #print(f_idxs)\n","        #         print(self.depth)\n","        self.n_features = n_features\n","        self.n, self.c = len(idxs), x.shape[1]\n","        self.val = np.mean(y[idxs])\n","        self.score = float('inf')\n","        self.find_varsplit()\n","\n","    def find_varsplit(self):\n","        for i in self.f_idxs: self.find_better_split(i)\n","        if self.is_leaf: return\n","        x = self.split_col\n","        lhs = np.nonzero(x <= self.split)[0]\n","        rhs = np.nonzero(x > self.split)[0]\n","        lf_idxs = np.random.permutation(self.x.shape[1])[:self.n_features]\n","        rf_idxs = np.random.permutation(self.x.shape[1])[:self.n_features]\n","        self.lhs = DecisionTree(self.x, self.y, self.n_features, lf_idxs, self.idxs[lhs], depth=self.depth - 1,\n","                                min_leaf=self.min_leaf)\n","        self.rhs = DecisionTree(self.x, self.y, self.n_features, rf_idxs, self.idxs[rhs], depth=self.depth - 1,\n","                                min_leaf=self.min_leaf)\n","\n","    def find_better_split(self, var_idx):\n","        x, y = self.x[self.idxs, var_idx], self.y[self.idxs]\n","        sort_idx = np.argsort(x)\n","        sort_y, sort_x = y[sort_idx], x[sort_idx]\n","        rhs_sum2: object\n","        rhs_cnt, rhs_sum, rhs_sum2 = self.n, sort_y.sum(), (sort_y ** 2).sum()\n","        lhs_cnt, lhs_sum, lhs_sum2 = 0, 0., 0.\n","\n","        for i in range(0, self.n - self.min_leaf - 1):\n","            xi, yi = sort_x[i], sort_y[i]\n","            lhs_cnt += 1\n","            rhs_cnt -= 1\n","            lhs_sum += yi\n","            rhs_sum -= yi\n","            lhs_sum2 += yi ** 2\n","            rhs_sum2 -= yi ** 2\n","            if i < self.min_leaf or xi == sort_x[i + 1]:\n","                continue\n","\n","            lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)\n","            rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)\n","            curr_score = lhs_std * lhs_cnt + rhs_std * rhs_cnt\n","            if curr_score < self.score:\n","                self.var_idx, self.score, self.split = var_idx, curr_score, xi\n","\n","    @property\n","    def split_name(self):\n","        return self.x.columns[self.var_idx]\n","\n","    @property\n","    def split_col(self):\n","        return self.x[self.idxs, self.var_idx]\n","\n","    @property\n","    def is_leaf(self):\n","        return self.score == float('inf') or self.depth <= 0\n","\n","    def predict(self, x):\n","        return np.array([self.predict_row(xi) for xi in x])\n","\n","    def predict_row(self, xi):\n","        if self.is_leaf: return self.val\n","        t = self.lhs if xi[self.var_idx] <= self.split else self.rhs\n","        return t.predict_row(xi)\n","\n","def std_agg(cnt, s1, s2):\n","    try:\n","        return math.sqrt((s2 / cnt) - (s1 / cnt) ** 2)\n","    except:\n","        return 0\n","\n","xi = X_train\n","train_index = X_train.shape\n","yi = y_train - np.mean(y_train)\n","ei = 0  # initialization of error\n","predf = np.mean(y_train)  # initial prediction 0\n","\n","\n","def create_tree(x, y, n_features, sample_sz, depth=3, min_leaf=5):\n","    idxs = np.random.permutation(len(y))[:sample_sz]\n","    f_idxs = np.random.permutation(x.shape[1])[:n_features]\n","    return DecisionTree(x[idxs], y[idxs], n_features, f_idxs,\n","                        idxs=np.array(range(sample_sz)), depth=depth, min_leaf=min_leaf)\n","\n","\n","print(\"hour_ahead = \" + str(hour_ahead))\n","print(\"n_estimators = \" + str(n_estimators))\n","print(\"learning_rate = \" + str(learning_rate))\n","print(\"Depth = \" + str(Depth))\n","print(\"Min_leaf = \" + str(Min_leaf))\n","\n","\n","trees = []\n","for i in range(n_estimators):\n","    tree = create_tree(xi, yi, train_index[1], train_index[0], depth=Depth, min_leaf=Min_leaf)\n","    predi = tree.predict(xi)\n","    predf = predf + learning_rate * predi\n","    print(str(i)+str(\"  \")+str(mean_absolute_error(y_train, predf)))\n","    ei = y_train - predf  # needed originl y here as residual always from original y\n","    yi = ei  # update yi as residual to reloop\n","    trees.append(tree)\n","\n","\n","MSE = mean_squared_error(y_train, predf, squared=True)\n","print(\"Training MSE  \" + str(MSE))\n","RMSE = np.sqrt(MSE)\n","print(\"Training RMSE  \" + str(RMSE))\n","MAE = mean_absolute_error(y_train, predf)\n","print(\"Training MAE  \" + str(MAE))\n","\n","\n","\n","xi = X_test\n","train_index = X_test.shape\n","yi = y_test - np.mean(y_test)\n","ei = 0  # initialization of error\n","predf = np.mean(y_test)\n","\n","i = 0\n","for t in trees:\n","    predi = t.predict(X_test)\n","    predf = predf + learning_rate * predi\n","    print(str(i)+str(\"  \")+str(np.sqrt(mean_squared_error(y_test, predf, squared=True))))\n","    print(str(i)+str(\"  \")+str(mean_absolute_error(y_test, predf)))\n","    ei = y_test - predf  # needed originl y here as residual always from original y\n","    yi = ei  # update yi as residual to reloop\n","\n","    #if i == 1:\n","    #   break\n","    i += 1\n","\n","\n","MSE = mean_squared_error(y_test, predf, squared=True)\n","print(\"Testing MSE  \" + str(MSE))\n","RMSE = np.sqrt(MSE)\n","print(\"Testing RMSE  \" + str(RMSE))\n","MAE = mean_absolute_error(y_test, predf)\n","print(\"Testing MAE  \" + str(MAE))\n","\n","\n","plt.figure(figsize=(10, 6), dpi=80)\n","plt.suptitle('Gradient boosting regressor (Test) N=' + str(Pred_index[0]))\n","plt.plot(np.arange(len(y_test))+1, y_test, color=\"blue\", linewidth=2.5, linestyle=\"-\", label='Real Price')\n","plt.plot(np.arange(len(predf))+1, predf, color=\"red\",  linewidth=2.5, linestyle=\"-\", label='Predicted Price')\n","plt.xlabel('Hours')\n","plt.ylabel('Price(EUR)')\n","plt.legend(frameon=False)\n","plt.show()"],"execution_count":null,"outputs":[]}]}